{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-11T12:42:29.753575Z","iopub.execute_input":"2022-05-11T12:42:29.754038Z","iopub.status.idle":"2022-05-11T12:42:29.760932Z","shell.execute_reply.started":"2022-05-11T12:42:29.754004Z","shell.execute_reply":"2022-05-11T12:42:29.759831Z"},"trusted":true},"execution_count":343,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:29.805601Z","iopub.execute_input":"2022-05-11T12:42:29.805907Z","iopub.status.idle":"2022-05-11T12:42:29.812417Z","shell.execute_reply.started":"2022-05-11T12:42:29.805877Z","shell.execute_reply":"2022-05-11T12:42:29.811211Z"},"trusted":true},"execution_count":344,"outputs":[]},{"cell_type":"code","source":"pip install -qq -U tensorflow-addons","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:29.869653Z","iopub.execute_input":"2022-05-11T12:42:29.870076Z","iopub.status.idle":"2022-05-11T12:42:42.937493Z","shell.execute_reply.started":"2022-05-11T12:42:29.870041Z","shell.execute_reply":"2022-05-11T12:42:42.936387Z"},"trusted":true},"execution_count":345,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:42.940411Z","iopub.execute_input":"2022-05-11T12:42:42.940773Z","iopub.status.idle":"2022-05-11T12:42:42.950739Z","shell.execute_reply.started":"2022-05-11T12:42:42.940712Z","shell.execute_reply":"2022-05-11T12:42:42.948505Z"},"trusted":true},"execution_count":346,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:42.953473Z","iopub.execute_input":"2022-05-11T12:42:42.954660Z","iopub.status.idle":"2022-05-11T12:42:42.962971Z","shell.execute_reply.started":"2022-05-11T12:42:42.954612Z","shell.execute_reply":"2022-05-11T12:42:42.961529Z"},"trusted":true},"execution_count":347,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nclass ConfigureHyperParameters(object):\n    # HP related to Data\n    batch_size=256\n    buffer_size=2*batch_size\n    input_shape=(32,32,3) # 32*32\n    num_classes=10 # 10 different categories\n    \n    # HP related to Augmentation\n    image_size=48\n    \n    # HP related to Architecture\n    patch_size=4\n    projected_dim=96\n    num_shift_blocks_per_stages=[2,4,8,2]\n    epsilon=1e-5\n    stochastic_depth_rate=0.2\n    mlp_dropout_rate=0.2\n    num_div=12\n    shift_pixel=1\n    mlp_expand_ratio=2\n    \n    # HP related to Optimizer\n    lr_start=1e-5\n    lr_max=1e-3\n    weight_decay=1e-4\n    \n    # HP related to Training\n    epochs=100","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:42.967055Z","iopub.execute_input":"2022-05-11T12:42:42.968506Z","iopub.status.idle":"2022-05-11T12:42:42.979857Z","shell.execute_reply.started":"2022-05-11T12:42:42.968352Z","shell.execute_reply":"2022-05-11T12:42:42.978720Z"},"trusted":true},"execution_count":348,"outputs":[]},{"cell_type":"code","source":"config=ConfigureHyperParameters()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:42.981909Z","iopub.execute_input":"2022-05-11T12:42:42.983000Z","iopub.status.idle":"2022-05-11T12:42:42.992545Z","shell.execute_reply.started":"2022-05-11T12:42:42.982953Z","shell.execute_reply":"2022-05-11T12:42:42.991488Z"},"trusted":true},"execution_count":349,"outputs":[]},{"cell_type":"code","source":"(x_train,y_train),(x_test,y_test)=keras.datasets.cifar10.load_data()\nprint(len(x_train))\nprint(len(x_test))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:42.994454Z","iopub.execute_input":"2022-05-11T12:42:42.995532Z","iopub.status.idle":"2022-05-11T12:42:43.802248Z","shell.execute_reply.started":"2022-05-11T12:42:42.995483Z","shell.execute_reply":"2022-05-11T12:42:43.800299Z"},"trusted":true},"execution_count":350,"outputs":[]},{"cell_type":"code","source":"(x_train,y_train),(x_val,y_val) = (x_train[:40000],y_train[:40000]),(x_train[40000:],y_train[40000:])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:43.804530Z","iopub.execute_input":"2022-05-11T12:42:43.805195Z","iopub.status.idle":"2022-05-11T12:42:43.812616Z","shell.execute_reply.started":"2022-05-11T12:42:43.805122Z","shell.execute_reply":"2022-05-11T12:42:43.811002Z"},"trusted":true},"execution_count":351,"outputs":[]},{"cell_type":"code","source":"print(len(x_train))\nprint(len(x_val))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:43.814416Z","iopub.execute_input":"2022-05-11T12:42:43.815427Z","iopub.status.idle":"2022-05-11T12:42:43.831233Z","shell.execute_reply.started":"2022-05-11T12:42:43.815375Z","shell.execute_reply":"2022-05-11T12:42:43.829757Z"},"trusted":true},"execution_count":352,"outputs":[]},{"cell_type":"code","source":"auto=tf.data.AUTOTUNE\n\ntrain_dataset=tf.data.Dataset.from_tensor_slices((x_train,y_train)) # 2/3\ntrain_dataset=train_dataset.shuffle(config.buffer_size).batch(config.batch_size).prefetch(auto)\n\nvalidation_dataset=tf.data.Dataset.from_tensor_slices((x_val,y_val)) # 1/6\nvalidation_dataset=validation_dataset.batch(config.batch_size).prefetch(auto)\n\ntest_dataset=tf.data.Dataset.from_tensor_slices((x_test,y_test)) # 1/6\ntest_dataset=test_dataset.batch(config.batch_size).prefetch(auto)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:43.833185Z","iopub.execute_input":"2022-05-11T12:42:43.833875Z","iopub.status.idle":"2022-05-11T12:42:44.681807Z","shell.execute_reply.started":"2022-05-11T12:42:43.833824Z","shell.execute_reply":"2022-05-11T12:42:44.680611Z"},"trusted":true},"execution_count":353,"outputs":[]},{"cell_type":"code","source":"def data_augmentation():\n    data_aug=keras.Sequential(\n    [\n        layers.Resizing(config.input_shape[0]+20,config.input_shape[0]+20),\n        layers.RandomCrop(config.image_size,config.image_size),\n        layers.RandomFlip(\"horizontal\"),\n        layers.Rescaling(1/255.0), # 255.0 - max pixel value\n    ])\n    return data_aug","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.686672Z","iopub.execute_input":"2022-05-11T12:42:44.687005Z","iopub.status.idle":"2022-05-11T12:42:44.694264Z","shell.execute_reply.started":"2022-05-11T12:42:44.686947Z","shell.execute_reply":"2022-05-11T12:42:44.693123Z"},"trusted":true},"execution_count":354,"outputs":[]},{"cell_type":"code","source":"class MLP(layers.Layer):\n    \"\"\" MLP for each shift block\"\"\"\n    \n    def __init__(self,mlp_expand_ratio,mlp_dropout_rate,**kwargs):\n        super().__init__(**kwargs)\n        self.mlp_expand_ratio=mlp_expand_ratio\n        self.mlp_dropout_rate=mlp_dropout_rate\n    \n    def build(self,input_shape):\n        input_channels=input_shape[-1] # last-index, no of channels (32,32,3)\n        initial_filters=int(self.mlp_expand_ratio*input_channels) # 6\n        \n        self.mlp=keras.Sequential(\n        [\n            layers.Dense(units=initial_filters,activation=tf.nn.gelu,), # Gaussian Error Linear Unit\n            layers.Dropout(rate=self.mlp_dropout_rate),\n            layers.Dense(units=input_channels),\n            layers.Dropout(rate=self.mlp_dropout_rate)\n        ])\n    \n    def call(self,x):\n        x=self.mlp(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.696482Z","iopub.execute_input":"2022-05-11T12:42:44.697243Z","iopub.status.idle":"2022-05-11T12:42:44.710705Z","shell.execute_reply.started":"2022-05-11T12:42:44.697180Z","shell.execute_reply":"2022-05-11T12:42:44.709523Z"},"trusted":true},"execution_count":355,"outputs":[]},{"cell_type":"code","source":"class DropPath(layers.Layer):\n    \n    def __init__(self,drop_path_prob,**kwargs):\n        super().__init__(**kwargs)\n        self.drop_path_prob=drop_path_prob\n    \n    def call(self,x,training=False): # drop the random tensors\n        if training:\n            keep_prob=1-self.drop_path_prob\n            shape=(tf.shape(x)[0],)+(1,)*(len(tf.shape(x))-1)\n            random_tensor=keep_prob + tf.random.uniform(shape,0,1)\n            random_tensor=tf.floor(random_tensor)\n            return (x/keep_prob)* random_tensor\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.712551Z","iopub.execute_input":"2022-05-11T12:42:44.713300Z","iopub.status.idle":"2022-05-11T12:42:44.725678Z","shell.execute_reply.started":"2022-05-11T12:42:44.713233Z","shell.execute_reply":"2022-05-11T12:42:44.724232Z"},"trusted":true},"execution_count":356,"outputs":[]},{"cell_type":"code","source":"class shiftViTBlock(layers.Layer):\n    \n    def __init__(self,epsilon,drop_path_prob,mlp_dropout_rate,num_div=12,shift_pixel=1,mlp_expand_ratio=2,**kwargs):\n        super().__init__(**kwargs)\n        self.shift_pixel=shift_pixel\n        self.mlp_expand_ratio=mlp_expand_ratio\n        self.mlp_dropout_rate=mlp_dropout_rate\n        self.num_div=num_div\n        self.epsilon=epsilon\n        self.drop_path_prob=drop_path_prob\n    \n    def build(self,input_shape):\n        self.H=input_shape[1]\n        self.W=input_shape[2]\n        self.C=input_shape[3]\n        self.layer_norm=layers.LayerNormalization(epsilon=self.epsilon)\n        self.drop_path=(DropPath(drop_path_prob=self.drop_path_prob) if self.drop_path_prob>0.0 else layers.Activation('linear'))\n        self.mlp=MLP(mlp_expand_ratio=self.mlp_expand_ratio,mlp_dropout_rate=self.mlp_dropout_rate)\n    \n    def get_shift_pad(self,x,mode):\n        if mode=='left':\n            offset_height=0\n            offset_width=0\n            target_height=0\n            target_width=self.shift_pixel\n        elif mode=='right':\n            offset_height=0\n            offset_width=self.shift_pixel\n            target_height=0\n            target_width=self.shift_pixel\n        elif mode=='up':\n            offset_height=0\n            offset_width=0\n            target_height=self.shift_pixel\n            target_width=0\n        else:\n            offset_height=self.shift_pixel\n            offset_width=0\n            target_height=self.shift_pixel\n            target_width=0\n        \n        crop=tf.image.crop_to_bounding_box(x,offset_height=offset_height,offset_width=offset_width,target_height=self.H-target_height,target_width=self.W-target_width)\n        shift_pad=tf.image.pad_to_bounding_box(crop,offset_height=offset_height,offset_width=offset_width,target_height=self.H,target_width=self.W)\n        return shift_pad\n    \n    def call(self,x,training=False):\n        # feature maps\n        x_splits=tf.split(x,num_or_size_splits=self.C//self.num_div,axis=-1)\n        \n        # shift feature maps\n        x_splits[0]=self.get_shift_pad(x_splits[0],mode=\"left\")\n        x_splits[1]=self.get_shift_pad(x_splits[1],mode='right')\n        x_splits[2]=self.get_shift_pad(x_splits[2],mode='up')\n        x_splits[3]=self.get_shift_pad(x_splits[3],mode='down')\n        \n        x=tf.concat(x_splits,axis=-1)\n        \n        temp=x\n        x=temp+self.drop_path(self.mlp(self.layer_norm(x)),training=training)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.728730Z","iopub.execute_input":"2022-05-11T12:42:44.729411Z","iopub.status.idle":"2022-05-11T12:42:44.753977Z","shell.execute_reply.started":"2022-05-11T12:42:44.729361Z","shell.execute_reply":"2022-05-11T12:42:44.752417Z"},"trusted":true},"execution_count":357,"outputs":[]},{"cell_type":"code","source":"class PatchMerging(layers.Layer):\n    \n    def __init__(self,epsilon,**kwargs):\n        super().__init__(**kwargs)\n        self.epsilon=epsilon\n    \n    def build(self,input_shape):\n        filters=2*input_shape[-1] # (32,32,3) -> 6\n        self.reduction=layers.Conv2D(filters=filters,kernel_size=2,strides=2,padding=\"same\",use_bias=False)\n        self.layer_norm=layers.LayerNormalization(epsilon=self.epsilon)\n    \n    def call(self,x):\n        x=self.layer_norm(x)\n        x=self.reduction(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.756178Z","iopub.execute_input":"2022-05-11T12:42:44.756825Z","iopub.status.idle":"2022-05-11T12:42:44.770893Z","shell.execute_reply.started":"2022-05-11T12:42:44.756731Z","shell.execute_reply":"2022-05-11T12:42:44.769832Z"},"trusted":true},"execution_count":358,"outputs":[]},{"cell_type":"code","source":"class StackedShiftBlocks(layers.Layer):\n    \n    def __init__(self,epsilon,mlp_dropout_rate,num_shift_blocks,stochastic_depth_rate,is_merge,num_div=12,shift_pixel=1,mlp_expand_ratio=2,**kwargs):\n        super().__init__(**kwargs)\n        self.epsilon=epsilon\n        self.mlp_dropout_rate=mlp_dropout_rate\n        self.num_shift_blocks=num_shift_blocks\n        self.stochastic_depth_rate=stochastic_depth_rate\n        self.is_merge=is_merge\n        self.num_div=num_div\n        self.shift_pixel=shift_pixel\n        self.mlp_expand_ratio=mlp_expand_ratio\n    \n    def build(self,input_shapes):\n        dpr=[x for x in np.linspace(start=0,stop=self.stochastic_depth_rate,num=self.num_shift_blocks)]\n        self.shift_blocks=list()\n        for num in range(self.num_shift_blocks):\n            self.shift_blocks.append(shiftViTBlock(num_div=self.num_div,epsilon=self.epsilon,drop_path_prob=dpr[num],mlp_dropout_rate=self.mlp_dropout_rate,shift_pixel=self.shift_pixel,mlp_expand_ratio=self.mlp_expand_ratio))\n        if self.is_merge:\n            self.patch_merge=PatchMerging(epsilon=self.epsilon)\n    \n    def call(self,x,training=False):\n        for shift_block in self.shift_blocks:\n            x=shift_block(x,training=training)\n        if self.is_merge:\n            x=self.patch_merge(x)\n        return x\n            ","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.774693Z","iopub.execute_input":"2022-05-11T12:42:44.776233Z","iopub.status.idle":"2022-05-11T12:42:44.792498Z","shell.execute_reply.started":"2022-05-11T12:42:44.776175Z","shell.execute_reply":"2022-05-11T12:42:44.791217Z"},"trusted":true},"execution_count":359,"outputs":[]},{"cell_type":"code","source":"class ShiftViTModel(keras.Model):\n    \n    def __init__(self,data_augmentation,projected_dim,patch_size,num_shift_blocks_per_stages,epsilon,mlp_dropout_rate,stochastic_depth_rate,num_div=12,shift_pixel=1,mlp_expand_ratio=2,**kwargs):\n        super().__init__(**kwargs)\n        self.data_augmentation=data_augmentation\n        self.patch_projection=layers.Conv2D(filters=projected_dim,kernel_size=patch_size,strides=patch_size,padding='same')\n        self.stages=list()\n        for index,num_shift_blocks in enumerate(num_shift_blocks_per_stages):\n            if index==len(num_shift_blocks_per_stages)-1:\n                is_merge=False\n            else:\n                is_merge=True\n            self.stages.append(StackedShiftBlocks(epsilon=epsilon,mlp_dropout_rate=mlp_dropout_rate,num_shift_blocks=num_shift_blocks,stochastic_depth_rate=stochastic_depth_rate,is_merge=is_merge,num_div=num_div,shift_pixel=shift_pixel,mlp_expand_ratio=mlp_expand_ratio))\n        self.global_avg_pool=layers.GlobalAveragePooling2D()\n    \n    def get_config(self):\n        config=super().get_config()\n        config.update(\n        {\n            'data_augmentation': self.data_augmentation,\n            'patch_projection': self.patch_projection,\n            'stages':self.stages,\n            'global_avg_pool':self.global_avg_pool,\n        })\n        return config\n    \n    def _calculate_loss(self,data,training=False):\n        (images,labels)=data\n        augmented_images=self.data_augmentation(images,training=training)\n        projected_patches=self.patch_projection(augmented_images)\n        x=projected_patches\n        for stage in self.stages:\n            x=stage(x,training=training)\n        \n        logits=self.global_avg_pool(x)\n        total_loss=self.compiled_loss(labels,logits)\n        return total_loss,labels,logits\n    \n    def train_step(self,inputs):\n        with tf.GradientTape() as tape:\n            total_loss,labels,logits=self._calculate_loss(data=inputs,training=True)\n        \n        train_vars=[self.data_augmentation.trainable_variables,self.patch_projection.trainable_variables,self.global_avg_pool.trainable_variables]\n        train_vars=train_vars+[stage.trainable_variables for stage in self.stages]\n        \n        # optimise the gradients\n        grads=tape.gradient(total_loss,train_vars)\n        trainable_variable_list=[]\n        for (grad,var) in zip(grads,train_vars):\n            for g,v in zip(grad,var):\n                trainable_variable_list.append((g,v))\n        self.optimizer.apply_gradients(trainable_variable_list)\n        \n        self.compiled_metrics.update_state(labels,logits)\n        return {m.name:m.result() for m in self.metrics}\n    \n    def test_step(self,data):\n        _,labels,logits=self._calculate_loss(data=data,training=False)\n        self.compiled_metrics.update_state(labels,logits)\n        return {m.name:m.result() for m in self.metrics}\n            ","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.795309Z","iopub.execute_input":"2022-05-11T12:42:44.796123Z","iopub.status.idle":"2022-05-11T12:42:44.821060Z","shell.execute_reply.started":"2022-05-11T12:42:44.796070Z","shell.execute_reply":"2022-05-11T12:42:44.819852Z"},"trusted":true},"execution_count":360,"outputs":[]},{"cell_type":"code","source":"# call the model\nmodel=ShiftViTModel(\ndata_augmentation=data_augmentation(),\nprojected_dim=config.projected_dim,\npatch_size=config.patch_size,\nnum_shift_blocks_per_stages=config.num_shift_blocks_per_stages,\nepsilon=config.epsilon,\nmlp_dropout_rate=config.mlp_dropout_rate,\nstochastic_depth_rate=config.stochastic_depth_rate,\nnum_div=config.num_div,\nshift_pixel=config.shift_pixel,\nmlp_expand_ratio=config.mlp_expand_ratio)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.823595Z","iopub.execute_input":"2022-05-11T12:42:44.824272Z","iopub.status.idle":"2022-05-11T12:42:44.858726Z","shell.execute_reply.started":"2022-05-11T12:42:44.824223Z","shell.execute_reply":"2022-05-11T12:42:44.857497Z"},"trusted":true},"execution_count":361,"outputs":[]},{"cell_type":"code","source":"# learning rate scheduler\n\nclass LearningRateScheduler(keras.optimizers.schedules.LearningRateSchedule):\n    \n    def __init__(self,lr_start,lr_max,warmup_steps,total_steps):\n        super().__init__()\n        self.lr_start=lr_start\n        self.lr_max=lr_max\n        self.warmup_steps=warmup_steps\n        self.total_steps=total_steps\n        self.pi=tf.constant(np.pi)\n    \n    def __call__(self,step):\n        \n        if self.total_steps<self.warmup_steps:\n            raise ValueError('something went wrong')\n        \n        cos_lr=tf.cos(self.pi*(tf.cast(step,tf.float32)-self.warmup_steps)/tf.cast(self.total_steps-self.warmup_steps,tf.float32))\n        learning_rate=0.5*self.lr_max*(1+cos_lr)\n        \n        if self.warmup_steps>0:\n            if self.lr_max<self.lr_start:\n                raise ValueError('start value is greather max value')\n            slope=(self.lr_max-self.lr_start)/self.warmup_steps\n            warmup_rate=slope*tf.cast(step,tf.float32)+self.lr_start\n            learning_rate=tf.where(step<self.warmup_steps,warmup_rate,learning_rate)\n        return tf.where(step>self.total_steps,0.0,learning_rate,name='learning_rate')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.860953Z","iopub.execute_input":"2022-05-11T12:42:44.861428Z","iopub.status.idle":"2022-05-11T12:42:44.874987Z","shell.execute_reply.started":"2022-05-11T12:42:44.861381Z","shell.execute_reply":"2022-05-11T12:42:44.873359Z"},"trusted":true},"execution_count":362,"outputs":[]},{"cell_type":"code","source":"# compile and train the model\ntotal_steps=int((len(x_train)/config.batch_size)*config.epochs)\n\nwarmup_epoch_percentage=0.15\nwarmup_steps=int(total_steps*warmup_epoch_percentage)\n\nscheduled_lrs=LearningRateScheduler(lr_start=1e-5,lr_max=1e-3,warmup_steps=warmup_steps,total_steps=total_steps)\n\noptimizer=tfa.optimizers.AdamW(learning_rate=scheduled_lrs,weight_decay=config.weight_decay)\n\nmodel.compile(optimizer=optimizer,loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=[keras.metrics.SparseCategoricalAccuracy(name='accuracy'),keras.metrics.SparseTopKCategoricalAccuracy(5,name='top-5-accuracy')])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.877608Z","iopub.execute_input":"2022-05-11T12:42:44.878079Z","iopub.status.idle":"2022-05-11T12:42:44.907207Z","shell.execute_reply.started":"2022-05-11T12:42:44.877971Z","shell.execute_reply":"2022-05-11T12:42:44.906130Z"},"trusted":true},"execution_count":363,"outputs":[]},{"cell_type":"code","source":"history=model.fit(train_dataset,epochs=config.epochs,validation_data=validation_dataset,callbacks=[keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=5,mode='auto')])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:42:44.909129Z","iopub.execute_input":"2022-05-11T12:42:44.909689Z"},"trusted":true},"execution_count":null,"outputs":[]}]}